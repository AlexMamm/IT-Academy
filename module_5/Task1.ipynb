{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8e9ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.cuda.is_available = lambda : False\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0b25e6",
   "metadata": {},
   "source": [
    "Глобальные переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b00ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.01\n",
    "file_path = 'HarryPotter.txt'\n",
    "string_size = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7519f845",
   "metadata": {},
   "source": [
    "Шифр Цезаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c6dd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harry Potter and the Goblet of Fire'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Cipher():\n",
    "    def __init__(self, step):\n",
    "        self.step = step\n",
    "        self.alphabet = string.ascii_letters + '.!? '\n",
    "        self.len_a = len(self.alphabet)\n",
    "\n",
    "    def encrypt(self, plaintext):\n",
    "        ciphertext = ''\n",
    "        for c in plaintext:\n",
    "            if c in self.alphabet:\n",
    "                ciphertext += self.alphabet[(self.alphabet.index(c) + self.step) % self.len_a]\n",
    "            else:\n",
    "                ciphertext += c\n",
    "        return ciphertext\n",
    "\n",
    "    def decrypt(self, ciphertext):\n",
    "        plaintext = ''\n",
    "        for c in ciphertext:\n",
    "            if c in self.alphabet:\n",
    "                plaintext += self.alphabet[(self.alphabet.index(c) - self.step) % self.len_a]\n",
    "            else:\n",
    "                plaintext += c\n",
    "        return plaintext\n",
    "    \n",
    "cipher = Cipher(5)\n",
    "len_a = cipher.len_a\n",
    "alphabet = cipher.alphabet\n",
    "cipher.decrypt(cipher.encrypt('Harry Potter and the Goblet of Fire'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425cc969",
   "metadata": {},
   "source": [
    "Генерация тензоров на обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ae099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensor(file_path, step):\n",
    "    text_array = []\n",
    "    with open(file_path, errors = 'ignore') as file:\n",
    "        while True:\n",
    "            text = file.read(step)\n",
    "            if not text:\n",
    "                break\n",
    "            text_array.append(re.sub(r'[^a-zA-Z.!? ]', r' ', text))\n",
    "    del text_array[-1]\n",
    "    y_train = torch.tensor([sent_to_index(lines) for lines in text_array[:4*len(text_array) // 5]])\n",
    "    x_train = torch.tensor([sent_to_index(cipher.encrypt(lines)) for lines in text_array[:4*len(text_array) // 5]])\n",
    "\n",
    "    y_test = torch.tensor([sent_to_index(lines) for lines in text_array[4*len(text_array) // 5:]])\n",
    "    x_test = torch.tensor([sent_to_index(cipher.encrypt(lines)) for lines in text_array[4*len(text_array) // 5:]])\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def sent_to_index(sentence):\n",
    "    return [alphabet.find(y) for y in sentence]\n",
    "\n",
    "x_train, y_train, x_test, y_test = make_tensor(file_path, string_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c75774",
   "metadata": {},
   "source": [
    "DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c576b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self._len = len(x)\n",
    "        self.y = y\n",
    "        self.x = x\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "train = DataLoader(MyDataset(x_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test = DataLoader(MyDataset(x_test, y_test), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5183ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(60, 32)\n",
    "        self.rnn = torch.nn.RNN(32, 128, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(128, len_a)\n",
    "\n",
    "    def forward(self, sentence, state=None):\n",
    "        x = self.embed(sentence)\n",
    "        out, hidden = self.rnn(x)\n",
    "        return self.linear(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd66099",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel()\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63641b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 1401.8447, acc: 0.8596 | test loss: 104.4891, test acc: 0.9653 | 19.99 sec.\n",
      "Epoch: 2, loss: 293.8605, acc: 0.9686 | test loss: 53.0091, test acc: 0.9731 | 20.13 sec.\n",
      "Epoch: 3, loss: 183.7583, acc: 0.9774 | test loss: 37.7654, test acc: 0.9816 | 19.40 sec.\n",
      "Epoch: 4, loss: 138.1617, acc: 0.9838 | test loss: 29.4085, test acc: 0.9870 | 19.38 sec.\n",
      "Epoch: 5, loss: 109.4519, acc: 0.9882 | test loss: 23.6644, test acc: 0.9914 | 20.07 sec.\n",
      "Epoch: 6, loss: 88.7500, acc: 0.9923 | test loss: 19.4287, test acc: 0.9943 | 18.05 sec.\n",
      "Epoch: 7, loss: 73.1692, acc: 0.9942 | test loss: 16.2540, test acc: 0.9948 | 17.76 sec.\n",
      "Epoch: 8, loss: 61.2964, acc: 0.9957 | test loss: 13.7912, test acc: 0.9962 | 18.00 sec.\n",
      "Epoch: 9, loss: 52.1300, acc: 0.9967 | test loss: 11.8612, test acc: 0.9968 | 18.02 sec.\n",
      "Epoch: 10, loss: 44.9032, acc: 0.9972 | test loss: 10.3360, test acc: 0.9972 | 18.04 sec.\n",
      "Epoch: 11, loss: 39.1301, acc: 0.9974 | test loss: 9.0843, test acc: 0.9972 | 17.94 sec.\n",
      "Epoch: 12, loss: 34.4273, acc: 0.9977 | test loss: 8.0574, test acc: 0.9976 | 17.86 sec.\n",
      "Epoch: 13, loss: 30.5422, acc: 0.9983 | test loss: 7.2004, test acc: 0.9982 | 17.87 sec.\n",
      "Epoch: 14, loss: 27.3014, acc: 0.9985 | test loss: 6.4730, test acc: 0.9983 | 17.61 sec.\n",
      "Epoch: 15, loss: 24.5820, acc: 0.9988 | test loss: 5.8518, test acc: 0.9990 | 18.06 sec.\n",
      "Epoch: 16, loss: 22.2519, acc: 0.9992 | test loss: 5.3208, test acc: 0.9995 | 17.76 sec.\n",
      "Epoch: 17, loss: 20.2854, acc: 0.9994 | test loss: 4.8565, test acc: 0.9996 | 18.10 sec.\n",
      "Epoch: 18, loss: 18.5494, acc: 0.9995 | test loss: 4.4499, test acc: 0.9996 | 17.83 sec.\n",
      "Epoch: 19, loss: 17.0674, acc: 0.9995 | test loss: 4.0955, test acc: 0.9996 | 18.38 sec.\n",
      "Epoch: 20, loss: 15.7611, acc: 0.9995 | test loss: 3.7824, test acc: 0.9996 | 18.08 sec.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc, iter_num = .0, .0, .0\n",
    "    start_epoch_time = time.time()\n",
    "    model.train()\n",
    "    for x, y in train:\n",
    "        x = x\n",
    "        y = y.view(1, -1).squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        out = model.forward(x).view(-1, len_a)\n",
    "        l = loss(out, y)\n",
    "        train_loss += l.item()\n",
    "        batch_acc = (out.argmax(dim=1) == y)\n",
    "        train_acc += batch_acc.sum().item() / batch_acc.shape[0]\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        iter_num += 1\n",
    "    print(f\"Epoch: {epoch+1}, loss: {train_loss:.4f}, acc: \"\n",
    "        f\"{train_acc / iter_num:.4f}\",\n",
    "        end=\" | \")\n",
    "    test_loss, test_acc, iter_num = .0, .0, .0\n",
    "    model.eval()\n",
    "    for x, y in test:\n",
    "        x = x\n",
    "        y = y.view(1, -1).squeeze()\n",
    "        out = model.forward(x).view(-1, len_a)\n",
    "        l = loss(out, y)\n",
    "        test_loss += l.item()\n",
    "        batch_acc = (out.argmax(dim=1) == y)\n",
    "        test_acc += batch_acc.sum().item() / batch_acc.shape[0]\n",
    "        iter_num += 1\n",
    "    print(\n",
    "        f\"test loss: {test_loss:.4f}, test acc: {test_acc / iter_num:.4f} | \"\n",
    "        f\"{time.time() - start_epoch_time:.2f} sec.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c376015e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypted sentence is : \n",
      "NrflnsjefemzljexjfBjjiekfwreymjexnEjetkeHwtfynfekqtfynslenseymjeXtzymeFyqfsynhegjyBjjseFkwnhfefsieXtzymeFrjwnhfb\n",
      "\n",
      "****************************************\n",
      "\n",
      "Decrypted sentence: \n",
      "Imagine a huge seaweed farm the size of Croatia floating in the South Atlantic between Africa and South America.\n",
      "\n",
      "****************************************\n",
      "\n",
      "Predicted sentence: \n",
      "Imagine a huge seaweed farm the size of Croatia floating in the South Atlantic between Africa and South America.\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Imagine a huge seaweed farm the size of Croatia floating in the South Atlantic between Africa and South America.'\n",
    "\n",
    "encrypted_sentence = cipher.encrypt(sentence)\n",
    "encrypted_sentence_idx = sent_to_index(encrypted_sentence)\n",
    "\n",
    "result = model(torch.tensor([encrypted_sentence_idx])).argmax(dim=2)\n",
    "predicted_sentence = \"\".join([alphabet[i.item()] for i in result.flatten()])\n",
    "\n",
    "print(f'Encrypted sentence is : \\n{encrypted_sentence}')\n",
    "print('\\n' + \"*\" * 40 + '\\n')\n",
    "print(f'Decrypted sentence: \\n{cipher.decrypt(encrypted_sentence)}')\n",
    "print('\\n' + \"*\" * 40 + '\\n')\n",
    "print(f'Predicted sentence: \\n{predicted_sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717546be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
