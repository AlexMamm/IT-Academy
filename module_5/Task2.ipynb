{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HAmxHOitKyAd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глобальные переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A1jm27F8Zgj5"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "NUM_EPOCH = 100\n",
    "learning_rate = 0.001\n",
    "len_sequence = 50\n",
    "count_sequence = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIBjP1s6LcTW"
   },
   "source": [
    "Правило генерации последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SqZ37QS8LZNo"
   },
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    y = torch.zeros_like(x)\n",
    "    y[0] = x[0]\n",
    "    for i in range(1, len(x)):\n",
    "        y[i] = (x[i]+x[0]) % 10\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z848hxx7r0UM"
   },
   "source": [
    "Генерация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "c5PR70_ELiH8"
   },
   "outputs": [],
   "source": [
    "count_train_sample, count_test_sample = int(count_sequence*0.7), int(count_sequence*0.3)\n",
    "\n",
    "x_train = torch.stack([torch.randint(low=0, high=9, size=(len_sequence,)) for i in range(count_train_sample)])\n",
    "y_train = torch.stack([encode(i) for i in x_train])\n",
    "\n",
    "x_test = torch.stack([torch.randint(low=0, high=9, size=(len_sequence,)) for i in range(count_test_sample)])\n",
    "y_test = torch.stack([encode(i) for i in x_test])\n",
    "\n",
    "train_ds = DataLoader(TensorDataset(x_train, y_train),\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      shuffle=True)\n",
    "test_ds = DataLoader(TensorDataset(x_test, y_test),\n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrGCOE8vr6b-"
   },
   "source": [
    "Тренировка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zYXpsxEZpzMD"
   },
   "outputs": [],
   "source": [
    "def train(train_ds, test_ds, model, optimizer, loss, num_epoch):\n",
    "    for epoch in range(num_epoch):\n",
    "        train_loss, train_acc, iter_num = .0, .0, .0\n",
    "        start_epoch_time = time.time()\n",
    "        model.train()\n",
    "        for x, y in train_ds:\n",
    "            x = x\n",
    "            y = y.view(1, -1).squeeze()\n",
    "            optimizer.zero_grad()\n",
    "            out = model.forward(x).view(-1, 10)\n",
    "            l = loss(out, y)\n",
    "            train_loss += l.item()\n",
    "            batch_acc = (out.argmax(dim=1) == y)\n",
    "            train_acc += batch_acc.sum().item() / batch_acc.shape[0]\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            iter_num += 1\n",
    "            \n",
    "        print(f\"Epoch: {epoch+1}, loss: {train_loss:.4f}, acc: \"\n",
    "              f\"{train_acc / iter_num:.4f}\",\n",
    "              end=\" | \")\n",
    "        \n",
    "        test_loss, test_acc, iter_num = .0, .0, .0\n",
    "        model.eval()\n",
    "        for x, y in test_ds:\n",
    "            x = x\n",
    "            y = y.view(1, -1).squeeze()\n",
    "            out = model.forward(x).view(-1, 10)\n",
    "            l = loss(out, y)\n",
    "            test_loss += l.item()\n",
    "            batch_acc = (out.argmax(dim=1) == y)\n",
    "            test_acc += batch_acc.sum().item() / batch_acc.shape[0]\n",
    "            iter_num += 1\n",
    "            \n",
    "        print(f\"test loss: {test_loss:.4f}, test acc: {test_acc / iter_num:.4f} | \"\n",
    "              f\"{time.time() - start_epoch_time:.2f} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJ0CUocyr9zd"
   },
   "source": [
    "### Модель RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "26nhBMhCYNOp"
   },
   "outputs": [],
   "source": [
    "class RNNModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(10, 10)\n",
    "        self.rnn = torch.nn.RNN(10, 128, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, sentence, state=None):\n",
    "        embed = self.embed(sentence)\n",
    "        o, h = self.rnn(embed)\n",
    "        return self.linear(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HXSY7j4iZddl"
   },
   "outputs": [],
   "source": [
    "model = RNNModel()\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejSgDBPsZn-S",
    "outputId": "6bfb7844-afaf-4764-d83c-e1dadb71acf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 124.7274, acc: 0.1101 | test loss: 53.8284, test acc: 0.1142 | 4.19 sec.\n",
      "Epoch: 2, loss: 122.8049, acc: 0.1158 | test loss: 53.4059, test acc: 0.1185 | 4.45 sec.\n",
      "Epoch: 3, loss: 122.2032, acc: 0.1148 | test loss: 53.2192, test acc: 0.1182 | 4.11 sec.\n",
      "Epoch: 4, loss: 121.7453, acc: 0.1167 | test loss: 53.0504, test acc: 0.1127 | 4.00 sec.\n",
      "Epoch: 5, loss: 121.3773, acc: 0.1184 | test loss: 52.9199, test acc: 0.1209 | 4.34 sec.\n",
      "Epoch: 6, loss: 121.1482, acc: 0.1255 | test loss: 52.9739, test acc: 0.1238 | 3.89 sec.\n",
      "Epoch: 7, loss: 120.1573, acc: 0.1576 | test loss: 51.9929, test acc: 0.1646 | 4.47 sec.\n",
      "Epoch: 8, loss: 113.9118, acc: 0.2078 | test loss: 46.6758, test acc: 0.2349 | 4.14 sec.\n",
      "Epoch: 9, loss: 101.5192, acc: 0.2346 | test loss: 42.5083, test acc: 0.2344 | 4.23 sec.\n",
      "Epoch: 10, loss: 95.4991, acc: 0.2411 | test loss: 41.5510, test acc: 0.2478 | 4.23 sec.\n",
      "Epoch: 11, loss: 94.2312, acc: 0.2511 | test loss: 41.7638, test acc: 0.2435 | 4.32 sec.\n",
      "Epoch: 12, loss: 90.7290, acc: 0.2883 | test loss: 36.9569, test acc: 0.3397 | 4.06 sec.\n",
      "Epoch: 13, loss: 79.8051, acc: 0.3492 | test loss: 36.3981, test acc: 0.3412 | 4.05 sec.\n",
      "Epoch: 14, loss: 80.4746, acc: 0.3462 | test loss: 32.6768, test acc: 0.3521 | 4.38 sec.\n",
      "Epoch: 15, loss: 71.7124, acc: 0.3550 | test loss: 30.5311, test acc: 0.3547 | 4.56 sec.\n",
      "Epoch: 16, loss: 68.9029, acc: 0.3616 | test loss: 29.8425, test acc: 0.3580 | 4.01 sec.\n",
      "Epoch: 17, loss: 67.7249, acc: 0.3655 | test loss: 29.6957, test acc: 0.3682 | 4.03 sec.\n",
      "Epoch: 18, loss: 66.8566, acc: 0.3688 | test loss: 29.1724, test acc: 0.3714 | 4.03 sec.\n",
      "Epoch: 19, loss: 66.2895, acc: 0.3742 | test loss: 28.9063, test acc: 0.3704 | 4.12 sec.\n",
      "Epoch: 20, loss: 65.8617, acc: 0.3886 | test loss: 28.8245, test acc: 0.3774 | 4.13 sec.\n",
      "Epoch: 21, loss: 62.3651, acc: 0.4542 | test loss: 26.1376, test acc: 0.4819 | 4.27 sec.\n",
      "Epoch: 22, loss: 58.7932, acc: 0.4868 | test loss: 25.7100, test acc: 0.4839 | 4.36 sec.\n",
      "Epoch: 23, loss: 59.9977, acc: 0.4746 | test loss: 25.6811, test acc: 0.4738 | 4.03 sec.\n",
      "Epoch: 24, loss: 57.8018, acc: 0.4785 | test loss: 25.0721, test acc: 0.4794 | 4.23 sec.\n",
      "Epoch: 25, loss: 56.8502, acc: 0.4857 | test loss: 24.8748, test acc: 0.4820 | 4.23 sec.\n",
      "Epoch: 26, loss: 56.3781, acc: 0.4889 | test loss: 24.5662, test acc: 0.4926 | 4.06 sec.\n",
      "Epoch: 27, loss: 56.0480, acc: 0.5007 | test loss: 24.5417, test acc: 0.4963 | 4.19 sec.\n",
      "Epoch: 28, loss: 57.3847, acc: 0.5198 | test loss: 23.4325, test acc: 0.5746 | 4.06 sec.\n",
      "Epoch: 29, loss: 44.2046, acc: 0.6009 | test loss: 15.9191, test acc: 0.6802 | 4.11 sec.\n",
      "Epoch: 30, loss: 33.1989, acc: 0.6984 | test loss: 13.9067, test acc: 0.6990 | 4.30 sec.\n",
      "Epoch: 31, loss: 30.8799, acc: 0.7101 | test loss: 13.8140, test acc: 0.6975 | 4.00 sec.\n",
      "Epoch: 32, loss: 30.2530, acc: 0.7062 | test loss: 12.9341, test acc: 0.7065 | 4.28 sec.\n",
      "Epoch: 33, loss: 31.0175, acc: 0.7072 | test loss: 20.4169, test acc: 0.6077 | 4.27 sec.\n",
      "Epoch: 34, loss: 30.9838, acc: 0.6947 | test loss: 12.7595, test acc: 0.7021 | 4.56 sec.\n",
      "Epoch: 35, loss: 28.4933, acc: 0.7137 | test loss: 12.3982, test acc: 0.7113 | 4.09 sec.\n",
      "Epoch: 36, loss: 27.0539, acc: 0.7440 | test loss: 9.7687, test acc: 0.7870 | 4.05 sec.\n",
      "Epoch: 37, loss: 20.4446, acc: 0.7974 | test loss: 8.6462, test acc: 0.7933 | 4.25 sec.\n",
      "Epoch: 38, loss: 18.9881, acc: 0.8023 | test loss: 8.2405, test acc: 0.7994 | 4.52 sec.\n",
      "Epoch: 39, loss: 18.2255, acc: 0.8084 | test loss: 7.9263, test acc: 0.8096 | 4.16 sec.\n",
      "Epoch: 40, loss: 17.6437, acc: 0.8176 | test loss: 7.8523, test acc: 0.8015 | 4.33 sec.\n",
      "Epoch: 41, loss: 17.5264, acc: 0.8191 | test loss: 7.7807, test acc: 0.8070 | 4.23 sec.\n",
      "Epoch: 42, loss: 18.2685, acc: 0.8072 | test loss: 8.0381, test acc: 0.7938 | 4.33 sec.\n",
      "Epoch: 43, loss: 17.2059, acc: 0.8076 | test loss: 7.5052, test acc: 0.8041 | 4.34 sec.\n",
      "Epoch: 44, loss: 16.8057, acc: 0.8135 | test loss: 7.3458, test acc: 0.8127 | 4.04 sec.\n",
      "Epoch: 45, loss: 16.4054, acc: 0.8212 | test loss: 7.2297, test acc: 0.8178 | 4.16 sec.\n",
      "Epoch: 46, loss: 22.1980, acc: 0.8085 | test loss: 10.9887, test acc: 0.7730 | 4.05 sec.\n",
      "Epoch: 47, loss: 88.6864, acc: 0.4708 | test loss: 35.7143, test acc: 0.4464 | 4.22 sec.\n",
      "Epoch: 48, loss: 75.5474, acc: 0.4610 | test loss: 31.1106, test acc: 0.4724 | 4.11 sec.\n",
      "Epoch: 49, loss: 67.5636, acc: 0.4923 | test loss: 27.2441, test acc: 0.5297 | 4.30 sec.\n",
      "Epoch: 50, loss: 59.5158, acc: 0.5444 | test loss: 24.1081, test acc: 0.5692 | 4.06 sec.\n",
      "Epoch: 51, loss: 54.8968, acc: 0.5627 | test loss: 22.9675, test acc: 0.5754 | 4.31 sec.\n",
      "Epoch: 52, loss: 52.4872, acc: 0.5717 | test loss: 22.2097, test acc: 0.5827 | 4.53 sec.\n",
      "Epoch: 53, loss: 51.7703, acc: 0.5769 | test loss: 21.9686, test acc: 0.5863 | 4.25 sec.\n",
      "Epoch: 54, loss: 50.6164, acc: 0.5808 | test loss: 21.4066, test acc: 0.5901 | 4.09 sec.\n",
      "Epoch: 55, loss: 49.5247, acc: 0.5854 | test loss: 20.9812, test acc: 0.5985 | 4.23 sec.\n",
      "Epoch: 56, loss: 48.6637, acc: 0.5931 | test loss: 20.5701, test acc: 0.6073 | 4.33 sec.\n",
      "Epoch: 57, loss: 44.9438, acc: 0.6300 | test loss: 17.4407, test acc: 0.6793 | 4.34 sec.\n",
      "Epoch: 58, loss: 43.3821, acc: 0.6637 | test loss: 15.9371, test acc: 0.6833 | 4.17 sec.\n",
      "Epoch: 59, loss: 33.7647, acc: 0.6809 | test loss: 13.7842, test acc: 0.6881 | 3.87 sec.\n",
      "Epoch: 60, loss: 31.4777, acc: 0.6842 | test loss: 13.3120, test acc: 0.6902 | 4.31 sec.\n",
      "Epoch: 61, loss: 30.5996, acc: 0.6856 | test loss: 13.0321, test acc: 0.6921 | 4.28 sec.\n",
      "Epoch: 62, loss: 30.0461, acc: 0.6873 | test loss: 12.7874, test acc: 0.6942 | 4.00 sec.\n",
      "Epoch: 63, loss: 30.5723, acc: 0.6882 | test loss: 12.8290, test acc: 0.6918 | 4.11 sec.\n",
      "Epoch: 64, loss: 29.5155, acc: 0.6881 | test loss: 12.5701, test acc: 0.6949 | 4.56 sec.\n",
      "Epoch: 65, loss: 29.1366, acc: 0.6912 | test loss: 12.4677, test acc: 0.6958 | 4.06 sec.\n",
      "Epoch: 66, loss: 28.8867, acc: 0.6910 | test loss: 12.3244, test acc: 0.6987 | 4.13 sec.\n",
      "Epoch: 67, loss: 28.6527, acc: 0.6929 | test loss: 12.2697, test acc: 0.6980 | 4.53 sec.\n",
      "Epoch: 68, loss: 28.4930, acc: 0.6936 | test loss: 12.2072, test acc: 0.6994 | 4.19 sec.\n",
      "Epoch: 69, loss: 28.2795, acc: 0.6952 | test loss: 12.1006, test acc: 0.7025 | 4.06 sec.\n",
      "Epoch: 70, loss: 28.1323, acc: 0.6972 | test loss: 12.0331, test acc: 0.7033 | 4.19 sec.\n",
      "Epoch: 71, loss: 28.3450, acc: 0.6955 | test loss: 12.0264, test acc: 0.7028 | 4.12 sec.\n",
      "Epoch: 72, loss: 27.9839, acc: 0.6978 | test loss: 12.0151, test acc: 0.7026 | 4.16 sec.\n",
      "Epoch: 73, loss: 27.7863, acc: 0.7004 | test loss: 11.8521, test acc: 0.7083 | 4.27 sec.\n",
      "Epoch: 74, loss: 27.5655, acc: 0.7031 | test loss: 11.7516, test acc: 0.7123 | 4.03 sec.\n",
      "Epoch: 75, loss: 27.3450, acc: 0.7110 | test loss: 11.7676, test acc: 0.7223 | 4.06 sec.\n",
      "Epoch: 76, loss: 25.0849, acc: 0.7539 | test loss: 8.6249, test acc: 0.8061 | 4.20 sec.\n",
      "Epoch: 77, loss: 19.0797, acc: 0.8034 | test loss: 7.8055, test acc: 0.8093 | 4.12 sec.\n",
      "Epoch: 78, loss: 18.1852, acc: 0.8055 | test loss: 7.5254, test acc: 0.8118 | 4.46 sec.\n",
      "Epoch: 79, loss: 17.2520, acc: 0.8098 | test loss: 7.2475, test acc: 0.8168 | 4.14 sec.\n",
      "Epoch: 80, loss: 16.8501, acc: 0.8154 | test loss: 7.1272, test acc: 0.8239 | 3.89 sec.\n",
      "Epoch: 81, loss: 18.7926, acc: 0.8100 | test loss: 7.3469, test acc: 0.8111 | 4.60 sec.\n",
      "Epoch: 82, loss: 16.8250, acc: 0.8115 | test loss: 7.0048, test acc: 0.8196 | 4.18 sec.\n",
      "Epoch: 83, loss: 16.1527, acc: 0.8252 | test loss: 6.4890, test acc: 0.8446 | 4.19 sec.\n",
      "Epoch: 84, loss: 10.9309, acc: 0.8917 | test loss: 4.1170, test acc: 0.9035 | 4.28 sec.\n",
      "Epoch: 85, loss: 9.3259, acc: 0.9036 | test loss: 3.9347, test acc: 0.9066 | 4.42 sec.\n",
      "Epoch: 86, loss: 9.1246, acc: 0.9053 | test loss: 5.5866, test acc: 0.8995 | 4.16 sec.\n",
      "Epoch: 87, loss: 23.0435, acc: 0.8314 | test loss: 12.5864, test acc: 0.7702 | 4.50 sec.\n",
      "Epoch: 88, loss: 24.8925, acc: 0.7864 | test loss: 8.5388, test acc: 0.7937 | 4.36 sec.\n",
      "Epoch: 89, loss: 18.7456, acc: 0.7938 | test loss: 7.7467, test acc: 0.8000 | 4.44 sec.\n",
      "Epoch: 90, loss: 17.6356, acc: 0.8017 | test loss: 7.3332, test acc: 0.8091 | 3.87 sec.\n",
      "Epoch: 91, loss: 12.4278, acc: 0.8756 | test loss: 4.2661, test acc: 0.8983 | 4.28 sec.\n",
      "Epoch: 92, loss: 9.3349, acc: 0.8990 | test loss: 3.9510, test acc: 0.8991 | 4.45 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93, loss: 9.0123, acc: 0.8990 | test loss: 3.8583, test acc: 0.9015 | 4.17 sec.\n",
      "Epoch: 94, loss: 8.8341, acc: 0.9005 | test loss: 3.8142, test acc: 0.9017 | 4.36 sec.\n",
      "Epoch: 95, loss: 8.7159, acc: 0.8999 | test loss: 3.7168, test acc: 0.9023 | 4.39 sec.\n",
      "Epoch: 96, loss: 8.5826, acc: 0.9014 | test loss: 3.6980, test acc: 0.9029 | 4.17 sec.\n",
      "Epoch: 97, loss: 8.4806, acc: 0.9038 | test loss: 3.6762, test acc: 0.9028 | 4.08 sec.\n",
      "Epoch: 98, loss: 8.4280, acc: 0.9033 | test loss: 3.6408, test acc: 0.9044 | 4.31 sec.\n",
      "Epoch: 99, loss: 8.3386, acc: 0.9046 | test loss: 3.6302, test acc: 0.9024 | 4.23 sec.\n",
      "Epoch: 100, loss: 8.3189, acc: 0.9051 | test loss: 3.5775, test acc: 0.9074 | 4.10 sec.\n"
     ]
    }
   ],
   "source": [
    "train(train_ds, test_ds, model, optimizer, loss, NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NyQw6UALBA_z",
    "outputId": "638f46e7-f700-4db8-aae1-66e56f96c691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate sequence: \n",
      " tensor([2, 1, 7, 1, 0, 4, 3, 3, 7, 7, 6, 0, 6, 1, 7, 5, 3, 8, 2, 6, 2, 1, 4, 8,\n",
      "        2, 5, 2, 8, 8, 7, 4, 2, 4, 7, 0, 3, 8, 5, 7, 3, 7, 1, 0, 4, 1, 0, 8, 3,\n",
      "        4, 7])\n",
      "Encode sequence: \n",
      " tensor([2, 3, 9, 3, 2, 6, 5, 5, 9, 9, 8, 2, 8, 3, 9, 7, 5, 0, 4, 8, 4, 3, 6, 0,\n",
      "        4, 7, 4, 0, 0, 9, 6, 4, 6, 9, 2, 5, 0, 7, 9, 5, 9, 3, 2, 6, 3, 2, 0, 5,\n",
      "        6, 9])\n",
      "Predicted sequence: \n",
      " tensor([2, 3, 9, 3, 2, 6, 5, 5, 9, 9, 8, 2, 8, 3, 9, 7, 5, 0, 4, 8, 4, 3, 6, 0,\n",
      "        4, 7, 4, 0, 0, 9, 6, 4, 6, 9, 2, 5, 0, 7, 9, 5, 9, 3, 2, 6, 3, 2, 0, 5,\n",
      "        6, 9])\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x = torch.randint(low=0, high=9, size=(len_sequence,))\n",
    "y = encode(x).view(-1)\n",
    "pred = model.forward(x).argmax(dim=1).view(-1)\n",
    "\n",
    "print('Generate sequence: \\n', x)\n",
    "print('Encode sequence: \\n', y)\n",
    "print('Predicted sequence: \\n', pred)\n",
    "print('Accuracy: ', accuracy_score(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vgqm_osFsrhE"
   },
   "source": [
    "### Модель LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2aeECCVlNtot"
   },
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(10, 10)\n",
    "        self.lstm = torch.nn.LSTM(10, 128, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, sentence, state=None):\n",
    "        embed = self.embed(sentence)\n",
    "        o, h = self.lstm(embed)\n",
    "        return self.linear(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eISkUSLzRggT"
   },
   "outputs": [],
   "source": [
    "model = LSTMModel()\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Je2lRMcFRdaq",
    "outputId": "83da45df-36ad-417d-9f86-2d653a5697b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 125.4248, acc: 0.1133 | test loss: 54.2078, test acc: 0.1133 | 18.67 sec.\n",
      "Epoch: 2, loss: 123.4114, acc: 0.1145 | test loss: 53.5696, test acc: 0.1157 | 17.39 sec.\n",
      "Epoch: 3, loss: 122.1155, acc: 0.1239 | test loss: 53.0671, test acc: 0.1287 | 17.08 sec.\n",
      "Epoch: 4, loss: 121.2212, acc: 0.1306 | test loss: 52.7499, test acc: 0.1315 | 17.58 sec.\n",
      "Epoch: 5, loss: 119.4699, acc: 0.1603 | test loss: 50.3672, test acc: 0.2082 | 18.30 sec.\n",
      "Epoch: 6, loss: 108.2123, acc: 0.2280 | test loss: 44.2783, test acc: 0.2372 | 17.82 sec.\n",
      "Epoch: 7, loss: 98.2187, acc: 0.2420 | test loss: 41.4794, test acc: 0.2504 | 18.36 sec.\n",
      "Epoch: 8, loss: 86.7658, acc: 0.3274 | test loss: 30.9737, test acc: 0.4396 | 17.21 sec.\n",
      "Epoch: 9, loss: 57.8396, acc: 0.5387 | test loss: 19.5730, test acc: 0.6076 | 17.69 sec.\n",
      "Epoch: 10, loss: 38.9290, acc: 0.6808 | test loss: 14.5707, test acc: 0.7591 | 17.50 sec.\n",
      "Epoch: 11, loss: 25.9469, acc: 0.8530 | test loss: 8.3346, test acc: 0.9241 | 17.58 sec.\n",
      "Epoch: 12, loss: 13.8325, acc: 0.9612 | test loss: 3.9399, test acc: 0.9947 | 16.89 sec.\n",
      "Epoch: 13, loss: 6.2073, acc: 0.9967 | test loss: 1.8480, test acc: 0.9977 | 17.88 sec.\n",
      "Epoch: 14, loss: 3.3153, acc: 0.9988 | test loss: 1.1475, test acc: 0.9995 | 17.07 sec.\n",
      "Epoch: 15, loss: 2.1896, acc: 0.9997 | test loss: 0.8043, test acc: 0.9999 | 17.84 sec.\n",
      "Epoch: 16, loss: 1.5915, acc: 1.0000 | test loss: 0.6064, test acc: 1.0000 | 17.36 sec.\n",
      "Epoch: 17, loss: 1.2267, acc: 1.0000 | test loss: 0.4778, test acc: 1.0000 | 17.30 sec.\n",
      "Epoch: 18, loss: 0.9829, acc: 1.0000 | test loss: 0.3895, test acc: 1.0000 | 17.89 sec.\n",
      "Epoch: 19, loss: 0.8100, acc: 1.0000 | test loss: 0.3252, test acc: 1.0000 | 17.38 sec.\n",
      "Epoch: 20, loss: 0.6820, acc: 1.0000 | test loss: 0.2764, test acc: 1.0000 | 17.74 sec.\n",
      "Epoch: 21, loss: 0.5837, acc: 1.0000 | test loss: 0.2384, test acc: 1.0000 | 17.66 sec.\n",
      "Epoch: 22, loss: 0.5061, acc: 1.0000 | test loss: 0.2080, test acc: 1.0000 | 17.58 sec.\n",
      "Epoch: 23, loss: 0.4437, acc: 1.0000 | test loss: 0.1832, test acc: 1.0000 | 17.35 sec.\n",
      "Epoch: 24, loss: 0.3925, acc: 1.0000 | test loss: 0.1627, test acc: 1.0000 | 17.72 sec.\n",
      "Epoch: 25, loss: 0.3498, acc: 1.0000 | test loss: 0.1455, test acc: 1.0000 | 17.71 sec.\n",
      "Epoch: 26, loss: 0.3138, acc: 1.0000 | test loss: 0.1311, test acc: 1.0000 | 17.82 sec.\n",
      "Epoch: 27, loss: 0.2832, acc: 1.0000 | test loss: 0.1186, test acc: 1.0000 | 17.32 sec.\n",
      "Epoch: 28, loss: 0.2568, acc: 1.0000 | test loss: 0.1079, test acc: 1.0000 | 17.60 sec.\n",
      "Epoch: 29, loss: 0.2339, acc: 1.0000 | test loss: 0.0985, test acc: 1.0000 | 17.11 sec.\n",
      "Epoch: 30, loss: 0.2139, acc: 1.0000 | test loss: 0.0902, test acc: 1.0000 | 17.47 sec.\n",
      "Epoch: 31, loss: 0.1963, acc: 1.0000 | test loss: 0.0829, test acc: 1.0000 | 17.76 sec.\n",
      "Epoch: 32, loss: 0.1808, acc: 1.0000 | test loss: 0.0766, test acc: 1.0000 | 17.54 sec.\n",
      "Epoch: 33, loss: 0.1669, acc: 1.0000 | test loss: 0.0708, test acc: 1.0000 | 17.47 sec.\n",
      "Epoch: 34, loss: 0.1546, acc: 1.0000 | test loss: 0.0657, test acc: 1.0000 | 18.12 sec.\n",
      "Epoch: 35, loss: 0.1436, acc: 1.0000 | test loss: 0.0611, test acc: 1.0000 | 17.63 sec.\n",
      "Epoch: 36, loss: 0.1336, acc: 1.0000 | test loss: 0.0570, test acc: 1.0000 | 17.97 sec.\n",
      "Epoch: 37, loss: 0.1247, acc: 1.0000 | test loss: 0.0532, test acc: 1.0000 | 17.99 sec.\n",
      "Epoch: 38, loss: 0.1166, acc: 1.0000 | test loss: 0.0498, test acc: 1.0000 | 17.90 sec.\n",
      "Epoch: 39, loss: 0.1091, acc: 1.0000 | test loss: 0.0467, test acc: 1.0000 | 17.43 sec.\n",
      "Epoch: 40, loss: 0.1024, acc: 1.0000 | test loss: 0.0438, test acc: 1.0000 | 18.34 sec.\n",
      "Epoch: 41, loss: 0.0962, acc: 1.0000 | test loss: 0.0413, test acc: 1.0000 | 17.96 sec.\n",
      "Epoch: 42, loss: 0.0905, acc: 1.0000 | test loss: 0.0389, test acc: 1.0000 | 18.10 sec.\n",
      "Epoch: 43, loss: 0.0852, acc: 1.0000 | test loss: 0.0366, test acc: 1.0000 | 18.68 sec.\n",
      "Epoch: 44, loss: 0.0804, acc: 1.0000 | test loss: 0.0346, test acc: 1.0000 | 18.56 sec.\n",
      "Epoch: 45, loss: 0.0759, acc: 1.0000 | test loss: 0.0327, test acc: 1.0000 | 17.49 sec.\n",
      "Epoch: 46, loss: 0.0718, acc: 1.0000 | test loss: 0.0309, test acc: 1.0000 | 17.63 sec.\n",
      "Epoch: 47, loss: 0.0679, acc: 1.0000 | test loss: 0.0293, test acc: 1.0000 | 17.49 sec.\n",
      "Epoch: 48, loss: 0.0644, acc: 1.0000 | test loss: 0.0278, test acc: 1.0000 | 17.82 sec.\n",
      "Epoch: 49, loss: 0.0610, acc: 1.0000 | test loss: 0.0264, test acc: 1.0000 | 15.54 sec.\n",
      "Epoch: 50, loss: 0.0579, acc: 1.0000 | test loss: 0.0251, test acc: 1.0000 | 16.88 sec.\n",
      "Epoch: 51, loss: 0.0550, acc: 1.0000 | test loss: 0.0238, test acc: 1.0000 | 18.07 sec.\n",
      "Epoch: 52, loss: 0.0523, acc: 1.0000 | test loss: 0.0227, test acc: 1.0000 | 17.55 sec.\n",
      "Epoch: 53, loss: 0.0497, acc: 1.0000 | test loss: 0.0216, test acc: 1.0000 | 18.95 sec.\n",
      "Epoch: 54, loss: 0.0473, acc: 1.0000 | test loss: 0.0206, test acc: 1.0000 | 18.65 sec.\n",
      "Epoch: 55, loss: 0.0450, acc: 1.0000 | test loss: 0.0197, test acc: 1.0000 | 18.43 sec.\n",
      "Epoch: 56, loss: 0.0428, acc: 1.0000 | test loss: 0.0187, test acc: 1.0000 | 17.85 sec.\n",
      "Epoch: 57, loss: 0.0408, acc: 1.0000 | test loss: 0.0178, test acc: 1.0000 | 18.34 sec.\n",
      "Epoch: 58, loss: 0.0389, acc: 1.0000 | test loss: 0.0170, test acc: 1.0000 | 16.03 sec.\n",
      "Epoch: 59, loss: 0.0371, acc: 1.0000 | test loss: 0.0162, test acc: 1.0000 | 17.91 sec.\n",
      "Epoch: 60, loss: 0.0355, acc: 1.0000 | test loss: 0.0155, test acc: 1.0000 | 17.64 sec.\n",
      "Epoch: 61, loss: 0.0339, acc: 1.0000 | test loss: 0.0148, test acc: 1.0000 | 17.77 sec.\n",
      "Epoch: 62, loss: 0.0324, acc: 1.0000 | test loss: 0.0144, test acc: 1.0000 | 16.01 sec.\n",
      "Epoch: 63, loss: 0.0310, acc: 1.0000 | test loss: 0.0136, test acc: 1.0000 | 18.73 sec.\n",
      "Epoch: 64, loss: 0.0297, acc: 1.0000 | test loss: 0.0129, test acc: 1.0000 | 17.28 sec.\n",
      "Epoch: 65, loss: 0.0284, acc: 1.0000 | test loss: 0.0125, test acc: 1.0000 | 17.27 sec.\n",
      "Epoch: 66, loss: 0.0272, acc: 1.0000 | test loss: 0.0118, test acc: 1.0000 | 17.35 sec.\n",
      "Epoch: 67, loss: 0.0261, acc: 1.0000 | test loss: 0.0114, test acc: 1.0000 | 18.27 sec.\n",
      "Epoch: 68, loss: 0.0250, acc: 1.0000 | test loss: 0.0108, test acc: 1.0000 | 16.61 sec.\n",
      "Epoch: 69, loss: 0.0240, acc: 1.0000 | test loss: 0.0104, test acc: 1.0000 | 16.88 sec.\n",
      "Epoch: 70, loss: 0.0231, acc: 1.0000 | test loss: 0.0099, test acc: 1.0000 | 17.47 sec.\n",
      "Epoch: 71, loss: 0.0221, acc: 1.0000 | test loss: 0.0095, test acc: 1.0000 | 17.89 sec.\n",
      "Epoch: 72, loss: 0.0213, acc: 1.0000 | test loss: 0.0092, test acc: 1.0000 | 16.77 sec.\n",
      "Epoch: 73, loss: 0.0204, acc: 1.0000 | test loss: 0.0088, test acc: 1.0000 | 17.65 sec.\n",
      "Epoch: 74, loss: 0.0197, acc: 1.0000 | test loss: 0.0085, test acc: 1.0000 | 17.10 sec.\n",
      "Epoch: 75, loss: 0.0189, acc: 1.0000 | test loss: 0.0082, test acc: 1.0000 | 18.02 sec.\n",
      "Epoch: 76, loss: 0.0182, acc: 1.0000 | test loss: 0.0078, test acc: 1.0000 | 16.89 sec.\n",
      "Epoch: 77, loss: 0.0175, acc: 1.0000 | test loss: 0.0075, test acc: 1.0000 | 17.83 sec.\n",
      "Epoch: 78, loss: 0.0169, acc: 1.0000 | test loss: 0.0073, test acc: 1.0000 | 16.86 sec.\n",
      "Epoch: 79, loss: 0.0162, acc: 1.0000 | test loss: 0.0070, test acc: 1.0000 | 17.82 sec.\n",
      "Epoch: 80, loss: 0.0156, acc: 1.0000 | test loss: 0.0067, test acc: 1.0000 | 18.29 sec.\n",
      "Epoch: 81, loss: 0.0151, acc: 1.0000 | test loss: 0.0065, test acc: 1.0000 | 16.89 sec.\n",
      "Epoch: 82, loss: 0.0145, acc: 1.0000 | test loss: 0.0063, test acc: 1.0000 | 17.65 sec.\n",
      "Epoch: 83, loss: 0.0140, acc: 1.0000 | test loss: 0.0060, test acc: 1.0000 | 16.99 sec.\n",
      "Epoch: 84, loss: 0.0135, acc: 1.0000 | test loss: 0.0058, test acc: 1.0000 | 16.92 sec.\n",
      "Epoch: 85, loss: 0.0130, acc: 1.0000 | test loss: 0.0056, test acc: 1.0000 | 18.18 sec.\n",
      "Epoch: 86, loss: 0.0126, acc: 1.0000 | test loss: 0.0054, test acc: 1.0000 | 17.83 sec.\n",
      "Epoch: 87, loss: 0.0121, acc: 1.0000 | test loss: 0.0052, test acc: 1.0000 | 18.23 sec.\n",
      "Epoch: 88, loss: 0.0117, acc: 1.0000 | test loss: 0.0050, test acc: 1.0000 | 16.89 sec.\n",
      "Epoch: 89, loss: 0.0113, acc: 1.0000 | test loss: 0.0049, test acc: 1.0000 | 16.91 sec.\n",
      "Epoch: 90, loss: 0.0109, acc: 1.0000 | test loss: 0.0047, test acc: 1.0000 | 17.24 sec.\n",
      "Epoch: 91, loss: 0.0105, acc: 1.0000 | test loss: 0.0045, test acc: 1.0000 | 17.39 sec.\n",
      "Epoch: 92, loss: 0.0102, acc: 1.0000 | test loss: 0.0044, test acc: 1.0000 | 18.32 sec.\n",
      "Epoch: 93, loss: 0.0098, acc: 1.0000 | test loss: 0.0042, test acc: 1.0000 | 18.12 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94, loss: 0.0095, acc: 1.0000 | test loss: 0.0041, test acc: 1.0000 | 18.85 sec.\n",
      "Epoch: 95, loss: 0.0092, acc: 1.0000 | test loss: 0.0040, test acc: 1.0000 | 17.85 sec.\n",
      "Epoch: 96, loss: 0.0088, acc: 1.0000 | test loss: 0.0038, test acc: 1.0000 | 18.12 sec.\n",
      "Epoch: 97, loss: 0.0086, acc: 1.0000 | test loss: 0.0037, test acc: 1.0000 | 18.22 sec.\n",
      "Epoch: 98, loss: 0.0083, acc: 1.0000 | test loss: 0.0036, test acc: 1.0000 | 18.13 sec.\n",
      "Epoch: 99, loss: 0.0080, acc: 1.0000 | test loss: 0.0034, test acc: 1.0000 | 18.29 sec.\n",
      "Epoch: 100, loss: 0.0077, acc: 1.0000 | test loss: 0.0033, test acc: 1.0000 | 17.19 sec.\n"
     ]
    }
   ],
   "source": [
    "train(train_ds, test_ds, model, optimizer, loss, NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnLmTQODel4a",
    "outputId": "a3121a07-abb3-4a3d-b9c1-a46868b70192"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate sequence: \n",
      " tensor([7, 3, 8, 5, 8, 2, 7, 8, 7, 0, 8, 0, 1, 0, 1, 6, 0, 5, 2, 7, 6, 3, 3, 6,\n",
      "        2, 1, 3, 6, 5, 3, 5, 0, 3, 5, 7, 6, 8, 5, 2, 2, 1, 0, 4, 7, 8, 2, 1, 2,\n",
      "        1, 2])\n",
      "Encode sequence: \n",
      " tensor([7, 0, 5, 2, 5, 9, 4, 5, 4, 7, 5, 7, 8, 7, 8, 3, 7, 2, 9, 4, 3, 0, 0, 3,\n",
      "        9, 8, 0, 3, 2, 0, 2, 7, 0, 2, 4, 3, 5, 2, 9, 9, 8, 7, 1, 4, 5, 9, 8, 9,\n",
      "        8, 9])\n",
      "Predicted sequence: \n",
      " tensor([7, 0, 5, 2, 5, 9, 4, 5, 4, 7, 5, 7, 8, 7, 8, 3, 7, 2, 9, 4, 3, 0, 0, 3,\n",
      "        9, 8, 0, 3, 2, 0, 2, 7, 0, 2, 4, 3, 5, 2, 9, 9, 8, 7, 1, 4, 5, 9, 8, 9,\n",
      "        8, 9])\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(low=0, high=9, size=(len_sequence,))\n",
    "y = encode(x).view(-1)\n",
    "pred = model.forward(x).argmax(dim=1).view(-1)\n",
    "\n",
    "print('Generate sequence: \\n', x)\n",
    "print('Encode sequence: \\n', y)\n",
    "print('Predicted sequence: \\n', pred)\n",
    "print('Accuracy: ', accuracy_score(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6r7oGrbsyWi"
   },
   "source": [
    "### Модель GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HG3fECK7RysC"
   },
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(10, 10)\n",
    "        self.gru = torch.nn.GRU(10, 128, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, sentence, state=None):\n",
    "        embed = self.embed(sentence)\n",
    "        o, h = self.gru(embed)\n",
    "        return self.linear(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ItgrKx26dYON"
   },
   "outputs": [],
   "source": [
    "model = GRUModel()\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_gf7QzLsdTtG",
    "outputId": "e997d489-23c9-4b5e-c138-ebb152f6a584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 125.2010, acc: 0.1110 | test loss: 54.0873, test acc: 0.1091 | 13.91 sec.\n",
      "Epoch: 2, loss: 123.2391, acc: 0.1148 | test loss: 53.5646, test acc: 0.1190 | 13.90 sec.\n",
      "Epoch: 3, loss: 122.1482, acc: 0.1223 | test loss: 53.0622, test acc: 0.1240 | 14.51 sec.\n",
      "Epoch: 4, loss: 121.2176, acc: 0.1276 | test loss: 52.7566, test acc: 0.1292 | 14.19 sec.\n",
      "Epoch: 5, loss: 120.4544, acc: 0.1362 | test loss: 52.1835, test acc: 0.1514 | 14.15 sec.\n",
      "Epoch: 6, loss: 113.4618, acc: 0.2165 | test loss: 47.0877, test acc: 0.2381 | 13.85 sec.\n",
      "Epoch: 7, loss: 103.1026, acc: 0.2650 | test loss: 42.7004, test acc: 0.3276 | 13.77 sec.\n",
      "Epoch: 8, loss: 79.9671, acc: 0.5238 | test loss: 23.8423, test acc: 0.7661 | 13.79 sec.\n",
      "Epoch: 9, loss: 30.1269, acc: 0.9415 | test loss: 5.2107, test acc: 0.9979 | 14.34 sec.\n",
      "Epoch: 10, loss: 6.7354, acc: 0.9996 | test loss: 1.6443, test acc: 1.0000 | 13.50 sec.\n",
      "Epoch: 11, loss: 2.7261, acc: 1.0000 | test loss: 0.8655, test acc: 1.0000 | 14.08 sec.\n",
      "Epoch: 12, loss: 1.5882, acc: 1.0000 | test loss: 0.5549, test acc: 1.0000 | 14.41 sec.\n",
      "Epoch: 13, loss: 1.0720, acc: 1.0000 | test loss: 0.3941, test acc: 1.0000 | 14.17 sec.\n",
      "Epoch: 14, loss: 0.7853, acc: 1.0000 | test loss: 0.2979, test acc: 1.0000 | 13.97 sec.\n",
      "Epoch: 15, loss: 0.6064, acc: 1.0000 | test loss: 0.2351, test acc: 1.0000 | 14.04 sec.\n",
      "Epoch: 16, loss: 0.4859, acc: 1.0000 | test loss: 0.1914, test acc: 1.0000 | 13.88 sec.\n",
      "Epoch: 17, loss: 0.4004, acc: 1.0000 | test loss: 0.1598, test acc: 1.0000 | 13.66 sec.\n",
      "Epoch: 18, loss: 0.3373, acc: 1.0000 | test loss: 0.1359, test acc: 1.0000 | 13.85 sec.\n",
      "Epoch: 19, loss: 0.2889, acc: 1.0000 | test loss: 0.1173, test acc: 1.0000 | 13.76 sec.\n",
      "Epoch: 20, loss: 0.2508, acc: 1.0000 | test loss: 0.1208, test acc: 0.9999 | 13.63 sec.\n",
      "Epoch: 21, loss: 0.2203, acc: 1.0000 | test loss: 0.1105, test acc: 0.9999 | 13.80 sec.\n",
      "Epoch: 22, loss: 0.1953, acc: 1.0000 | test loss: 0.0985, test acc: 0.9999 | 14.24 sec.\n",
      "Epoch: 23, loss: 0.1746, acc: 1.0000 | test loss: 0.0898, test acc: 0.9999 | 13.77 sec.\n",
      "Epoch: 24, loss: 0.1570, acc: 1.0000 | test loss: 0.0827, test acc: 0.9999 | 13.69 sec.\n",
      "Epoch: 25, loss: 0.1421, acc: 1.0000 | test loss: 0.0771, test acc: 0.9999 | 14.24 sec.\n",
      "Epoch: 26, loss: 0.1292, acc: 1.0000 | test loss: 0.0721, test acc: 0.9999 | 13.82 sec.\n",
      "Epoch: 27, loss: 0.1179, acc: 1.0000 | test loss: 0.0696, test acc: 0.9999 | 13.80 sec.\n",
      "Epoch: 28, loss: 0.1080, acc: 1.0000 | test loss: 0.0653, test acc: 0.9999 | 13.99 sec.\n",
      "Epoch: 29, loss: 0.0992, acc: 1.0000 | test loss: 0.0636, test acc: 0.9999 | 13.88 sec.\n",
      "Epoch: 30, loss: 0.0915, acc: 1.0000 | test loss: 0.0605, test acc: 0.9999 | 14.02 sec.\n",
      "Epoch: 31, loss: 0.0846, acc: 1.0000 | test loss: 0.0581, test acc: 0.9999 | 13.67 sec.\n",
      "Epoch: 32, loss: 0.0785, acc: 1.0000 | test loss: 0.0556, test acc: 0.9999 | 14.12 sec.\n",
      "Epoch: 33, loss: 0.0731, acc: 1.0000 | test loss: 0.0537, test acc: 0.9999 | 14.41 sec.\n",
      "Epoch: 34, loss: 0.0682, acc: 1.0000 | test loss: 0.0518, test acc: 0.9999 | 13.57 sec.\n",
      "Epoch: 35, loss: 0.0637, acc: 1.0000 | test loss: 0.0498, test acc: 0.9999 | 13.98 sec.\n",
      "Epoch: 36, loss: 0.0597, acc: 1.0000 | test loss: 0.0783, test acc: 0.9998 | 14.41 sec.\n",
      "Epoch: 37, loss: 0.0560, acc: 1.0000 | test loss: 0.0455, test acc: 0.9999 | 14.38 sec.\n",
      "Epoch: 38, loss: 0.0527, acc: 1.0000 | test loss: 0.0448, test acc: 0.9999 | 13.79 sec.\n",
      "Epoch: 39, loss: 0.0496, acc: 1.0000 | test loss: 0.0424, test acc: 0.9999 | 14.47 sec.\n",
      "Epoch: 40, loss: 0.0468, acc: 1.0000 | test loss: 0.0428, test acc: 0.9999 | 14.02 sec.\n",
      "Epoch: 41, loss: 0.0442, acc: 1.0000 | test loss: 0.0396, test acc: 0.9999 | 14.01 sec.\n",
      "Epoch: 42, loss: 0.0417, acc: 1.0000 | test loss: 0.0375, test acc: 0.9999 | 13.98 sec.\n",
      "Epoch: 43, loss: 0.0395, acc: 1.0000 | test loss: 0.0370, test acc: 0.9999 | 14.04 sec.\n",
      "Epoch: 44, loss: 0.0375, acc: 1.0000 | test loss: 0.0349, test acc: 0.9999 | 13.99 sec.\n",
      "Epoch: 45, loss: 0.0355, acc: 1.0000 | test loss: 0.0357, test acc: 0.9999 | 14.00 sec.\n",
      "Epoch: 46, loss: 0.0338, acc: 1.0000 | test loss: 0.0386, test acc: 0.9999 | 13.95 sec.\n",
      "Epoch: 47, loss: 0.0321, acc: 1.0000 | test loss: 0.0393, test acc: 0.9999 | 13.80 sec.\n",
      "Epoch: 48, loss: 0.0305, acc: 1.0000 | test loss: 0.0365, test acc: 0.9999 | 14.40 sec.\n",
      "Epoch: 49, loss: 0.0291, acc: 1.0000 | test loss: 0.0124, test acc: 1.0000 | 14.52 sec.\n",
      "Epoch: 50, loss: 0.0277, acc: 1.0000 | test loss: 0.0118, test acc: 1.0000 | 14.40 sec.\n",
      "Epoch: 51, loss: 0.0264, acc: 1.0000 | test loss: 0.0113, test acc: 1.0000 | 14.43 sec.\n",
      "Epoch: 52, loss: 0.0252, acc: 1.0000 | test loss: 0.0108, test acc: 1.0000 | 14.08 sec.\n",
      "Epoch: 53, loss: 0.0241, acc: 1.0000 | test loss: 0.0103, test acc: 1.0000 | 14.04 sec.\n",
      "Epoch: 54, loss: 0.0230, acc: 1.0000 | test loss: 0.0098, test acc: 1.0000 | 13.98 sec.\n",
      "Epoch: 55, loss: 0.0220, acc: 1.0000 | test loss: 0.0094, test acc: 1.0000 | 14.26 sec.\n",
      "Epoch: 56, loss: 0.0210, acc: 1.0000 | test loss: 0.0090, test acc: 1.0000 | 13.77 sec.\n",
      "Epoch: 57, loss: 0.0201, acc: 1.0000 | test loss: 0.0086, test acc: 1.0000 | 14.81 sec.\n",
      "Epoch: 58, loss: 0.0193, acc: 1.0000 | test loss: 0.0082, test acc: 1.0000 | 14.15 sec.\n",
      "Epoch: 59, loss: 0.0185, acc: 1.0000 | test loss: 0.0079, test acc: 1.0000 | 13.96 sec.\n",
      "Epoch: 60, loss: 0.0177, acc: 1.0000 | test loss: 0.0076, test acc: 1.0000 | 14.15 sec.\n",
      "Epoch: 61, loss: 0.0170, acc: 1.0000 | test loss: 0.0073, test acc: 1.0000 | 14.24 sec.\n",
      "Epoch: 62, loss: 0.0163, acc: 1.0000 | test loss: 0.0070, test acc: 1.0000 | 14.18 sec.\n",
      "Epoch: 63, loss: 0.0156, acc: 1.0000 | test loss: 0.0067, test acc: 1.0000 | 13.96 sec.\n",
      "Epoch: 64, loss: 0.0150, acc: 1.0000 | test loss: 0.0064, test acc: 1.0000 | 14.48 sec.\n",
      "Epoch: 65, loss: 0.0144, acc: 1.0000 | test loss: 0.0062, test acc: 1.0000 | 14.68 sec.\n",
      "Epoch: 66, loss: 0.0139, acc: 1.0000 | test loss: 0.0059, test acc: 1.0000 | 14.09 sec.\n",
      "Epoch: 67, loss: 0.0133, acc: 1.0000 | test loss: 0.0057, test acc: 1.0000 | 14.20 sec.\n",
      "Epoch: 68, loss: 0.0128, acc: 1.0000 | test loss: 0.0055, test acc: 1.0000 | 14.37 sec.\n",
      "Epoch: 69, loss: 0.0123, acc: 1.0000 | test loss: 0.0053, test acc: 1.0000 | 14.71 sec.\n",
      "Epoch: 70, loss: 0.0119, acc: 1.0000 | test loss: 0.0051, test acc: 1.0000 | 14.04 sec.\n",
      "Epoch: 71, loss: 0.0114, acc: 1.0000 | test loss: 0.0049, test acc: 1.0000 | 14.60 sec.\n",
      "Epoch: 72, loss: 0.0110, acc: 1.0000 | test loss: 0.0047, test acc: 1.0000 | 14.38 sec.\n",
      "Epoch: 73, loss: 0.0106, acc: 1.0000 | test loss: 0.0046, test acc: 1.0000 | 14.27 sec.\n",
      "Epoch: 74, loss: 0.0102, acc: 1.0000 | test loss: 0.0044, test acc: 1.0000 | 14.82 sec.\n",
      "Epoch: 75, loss: 0.0098, acc: 1.0000 | test loss: 0.0042, test acc: 1.0000 | 14.87 sec.\n",
      "Epoch: 76, loss: 0.0095, acc: 1.0000 | test loss: 0.0041, test acc: 1.0000 | 14.51 sec.\n",
      "Epoch: 77, loss: 0.0092, acc: 1.0000 | test loss: 0.0039, test acc: 1.0000 | 14.41 sec.\n",
      "Epoch: 78, loss: 0.0088, acc: 1.0000 | test loss: 0.0038, test acc: 1.0000 | 14.32 sec.\n",
      "Epoch: 79, loss: 0.0085, acc: 1.0000 | test loss: 0.0037, test acc: 1.0000 | 14.13 sec.\n",
      "Epoch: 80, loss: 0.0082, acc: 1.0000 | test loss: 0.0035, test acc: 1.0000 | 14.52 sec.\n",
      "Epoch: 81, loss: 0.0079, acc: 1.0000 | test loss: 0.0034, test acc: 1.0000 | 14.27 sec.\n",
      "Epoch: 82, loss: 0.0077, acc: 1.0000 | test loss: 0.0033, test acc: 1.0000 | 13.34 sec.\n",
      "Epoch: 83, loss: 0.0074, acc: 1.0000 | test loss: 0.0032, test acc: 1.0000 | 14.08 sec.\n",
      "Epoch: 84, loss: 0.0071, acc: 1.0000 | test loss: 0.0031, test acc: 1.0000 | 14.57 sec.\n",
      "Epoch: 85, loss: 0.0069, acc: 1.0000 | test loss: 0.0030, test acc: 1.0000 | 14.07 sec.\n",
      "Epoch: 86, loss: 0.0067, acc: 1.0000 | test loss: 0.0029, test acc: 1.0000 | 14.12 sec.\n",
      "Epoch: 87, loss: 0.0064, acc: 1.0000 | test loss: 0.0028, test acc: 1.0000 | 14.37 sec.\n",
      "Epoch: 88, loss: 0.0062, acc: 1.0000 | test loss: 0.0027, test acc: 1.0000 | 14.37 sec.\n",
      "Epoch: 89, loss: 0.0060, acc: 1.0000 | test loss: 0.0026, test acc: 1.0000 | 14.07 sec.\n",
      "Epoch: 90, loss: 0.0058, acc: 1.0000 | test loss: 0.0025, test acc: 1.0000 | 14.48 sec.\n",
      "Epoch: 91, loss: 0.0056, acc: 1.0000 | test loss: 0.0024, test acc: 1.0000 | 14.19 sec.\n",
      "Epoch: 92, loss: 0.0054, acc: 1.0000 | test loss: 0.0023, test acc: 1.0000 | 14.17 sec.\n",
      "Epoch: 93, loss: 0.0053, acc: 1.0000 | test loss: 0.0023, test acc: 1.0000 | 14.07 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94, loss: 0.0051, acc: 1.0000 | test loss: 0.0022, test acc: 1.0000 | 14.57 sec.\n",
      "Epoch: 95, loss: 0.0049, acc: 1.0000 | test loss: 0.0021, test acc: 1.0000 | 14.12 sec.\n",
      "Epoch: 96, loss: 0.0048, acc: 1.0000 | test loss: 0.0020, test acc: 1.0000 | 14.30 sec.\n",
      "Epoch: 97, loss: 0.0046, acc: 1.0000 | test loss: 0.0020, test acc: 1.0000 | 14.92 sec.\n",
      "Epoch: 98, loss: 0.0044, acc: 1.0000 | test loss: 0.0019, test acc: 1.0000 | 13.74 sec.\n",
      "Epoch: 99, loss: 0.0043, acc: 1.0000 | test loss: 0.0019, test acc: 1.0000 | 14.15 sec.\n",
      "Epoch: 100, loss: 0.0042, acc: 1.0000 | test loss: 0.0018, test acc: 1.0000 | 13.72 sec.\n"
     ]
    }
   ],
   "source": [
    "train(train_ds, test_ds, model, optimizer, loss, NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cEI2DPAZerjp",
    "outputId": "a17534fe-4376-4f0c-ccf4-af3c03ecc713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate sequence: \n",
      " tensor([2, 0, 6, 5, 2, 5, 8, 2, 4, 1, 6, 1, 8, 2, 1, 4, 2, 1, 5, 3, 8, 4, 7, 1,\n",
      "        7, 0, 4, 3, 5, 4, 6, 6, 6, 7, 5, 8, 0, 4, 8, 4, 3, 6, 0, 6, 3, 4, 1, 5,\n",
      "        5, 5])\n",
      "Encode sequence: \n",
      " tensor([2, 2, 8, 7, 4, 7, 0, 4, 6, 3, 8, 3, 0, 4, 3, 6, 4, 3, 7, 5, 0, 6, 9, 3,\n",
      "        9, 2, 6, 5, 7, 6, 8, 8, 8, 9, 7, 0, 2, 6, 0, 6, 5, 8, 2, 8, 5, 6, 3, 7,\n",
      "        7, 7])\n",
      "Predicted sequence: \n",
      " tensor([2, 2, 8, 7, 4, 7, 0, 4, 6, 3, 8, 3, 0, 4, 3, 6, 4, 3, 7, 5, 0, 6, 9, 3,\n",
      "        9, 2, 6, 5, 7, 6, 8, 8, 8, 9, 7, 0, 2, 6, 0, 6, 5, 8, 2, 8, 5, 6, 3, 7,\n",
      "        7, 7])\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(low=0, high=9, size=(len_sequence,))\n",
    "y = encode(x).view(-1)\n",
    "pred = model.forward(x).argmax(dim=1).view(-1)\n",
    "\n",
    "print('Generate sequence: \\n', x)\n",
    "print('Encode sequence: \\n', y)\n",
    "print('Predicted sequence: \\n', pred)\n",
    "print('Accuracy: ', accuracy_score(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
